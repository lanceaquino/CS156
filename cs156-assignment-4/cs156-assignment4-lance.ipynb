{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS156 Assignment 4 \n",
    "\n",
    "For this assignment, I'll be using the Image net data, specifically the man and woman images where I try to classify if a clothing is for man or woman. The data set consists of over 2,000 images and will be using PCA and LDA. \n",
    "\n",
    "Link to the working notebook can be accessed [here](https://github.com/lanceaquino/CS156-work-products-git/blob/main/cs156-assignment-4/cs156-assignment4-lance.ipynb). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from PIL import Image\n",
    "from resizeimage import resizeimage\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# create paths for all images\n",
    "man_clothes = glob('man/*')\n",
    "woman_clothes = glob('woman/*')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_resize(images, size):\n",
    "    \"\"\"\n",
    "    This function is used from Session 7.1 where we use to \n",
    "    resize images.\n",
    "    \"\"\"\n",
    "    flattened = []\n",
    "    # for each image path\n",
    "    for path in images:\n",
    "        # open it as a read file in binary mode\n",
    "        with open(path, 'r+b') as f:\n",
    "            # open it as an image\n",
    "            with Image.open(f) as image:\n",
    "                # resize the image to be more manageable\n",
    "                cover = resizeimage.resize_cover(image, size)\n",
    "                # flatten the matrix to an array and append it to all flattened images\n",
    "                flattened.append((np.array(cover).flatten(), 0))\n",
    "\n",
    "    # Flatten it once more\n",
    "    flattened = np.asarray(flattened, dtype = object)\n",
    "\n",
    "    # Declare which are the X and Y inputs\n",
    "    X = flattened[:,0]\n",
    "    Y = flattened[:,1]\n",
    "\n",
    "    # Use np.stack to put the data into the right dimension\n",
    "    X = np.stack(i for i in X)\n",
    "    Y = np.stack(i for i in Y)\n",
    "    \n",
    "    return X, Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lancelot/opt/anaconda3/lib/python3.8/site-packages/IPython/core/magics/execution.py:1321: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  exec(code, glob, local_ns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1242, 22500)\n",
      "(1270, 22500)\n",
      "CPU times: user 11.6 s, sys: 345 ms, total: 12 s\n",
      "Wall time: 12.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# chosen size reduction \n",
    "size = [50,150]\n",
    "\n",
    "man_images = image_resize(man_clothes, size)[0]\n",
    "woman_images = image_resize(woman_clothes, size)[0]\n",
    "\n",
    "#Check data shape \n",
    "print(man_images.shape) \n",
    "print(woman_images.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOTE \n",
    "\n",
    "This error can be ignored since we do not need to implement the function again and that we have the desired dimensions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1242, 22501)\n",
      "(1270, 22501)\n",
      "(2512, 22501)\n"
     ]
    }
   ],
   "source": [
    "## Add classes and merge data \n",
    "\n",
    "# Add 1 for men and 0 for women classes \n",
    "new_column_ones = np.ones((len(man_images), 1))\n",
    "new_column_zeros = np.zeros((len(woman_images), 1))\n",
    "\n",
    "class_man_images = np.append(man_images, new_column_ones, axis = 1)\n",
    "class_woman_images = np.append(woman_images, new_column_zeros, axis = 1)\n",
    "\n",
    "print(class_man_images.shape)\n",
    "print(class_woman_images.shape)\n",
    "\n",
    "images_data = np.concatenate((class_man_images, class_woman_images), axis = 0)\n",
    "\n",
    "print(images_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2512, 22500)\n",
      "(2512,)\n",
      "Split data: \n",
      "(2009, 22500)\n",
      "(503, 22500)\n",
      "(2009,)\n",
      "(503,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = images_data[:, 0:-1] # select all except the last column \n",
    "y = images_data[:, -1] # select last column \n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "# Splitting training and testing for 80% and 20% \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 24)\n",
    "\n",
    "print(\"Split data: \")\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Logistic Regression without PCA or LDA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---SCORES---\n",
      "Training Score: 0.75311100049776\n",
      "Testing Score: 0.6302186878727635\n",
      "CPU times: user 6min 58s, sys: 22.6 s, total: 7min 21s\n",
      "Wall time: 44.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "logregCV = make_pipeline(StandardScaler(), \n",
    "                         LogisticRegressionCV(cv = 5, random_state = 0, tol = 1))\n",
    "\n",
    "# Fit values\n",
    "logregCV.fit(X_train, y_train)\n",
    "\n",
    "# Acquire Metrics \n",
    "logregCV_training_score = logregCV.score(X_train, y_train)\n",
    "logregCV_testing_score = logregCV.score(X_test, y_test)\n",
    "\n",
    "print(\"---SCORES---\")\n",
    "print(\"Training Score:\", logregCV_training_score)\n",
    "print(\"Testing Score:\", logregCV_testing_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot confusion metrics \n",
    "metrics.plot_confusion_matrix(logregCV, X_test, y_test, cmap = 'binary')\n",
    "plt.title(\"Logreg without PCA or LDA\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression with PCA \n",
    "\n",
    "As the first step, we would just like to check on how the trend of the scree plot behaves when we apply PCA. Here we just test up until 20 n_components since beyond that would just be purely flat variance and would be really small to see. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (2009, 20) (503, 20)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAeRElEQVR4nO3debhcVZnv8e+PhCgGMEIiAgkEFaGDLYgRZAanTkCNtNgBB0DEdGzTii1Xc7u9dLq9fR+4DrcdkHTAtKIMohI6DYnAZRARkZxgGAIEI8ZODEOAhFGBkLf/WOvAprLqnKrk7KqT5Pd5nnrO3nutteutvevst/a0tiICMzOzRlt1OwAzMxucnCDMzKzICcLMzIqcIMzMrMgJwszMipwgzMysyAnCBjVJJ0u6sUPvtZekX0t6QtKnW2wTkl5fd2ztknSYpCXdjqNOkuZLOqnbcWzOnCC2MJIOlXSTpMckPSrpF5Le2uWYZkh6TtKTktbk+A7agPlcL+nUjQjl88D1EbFdRHyjhvkXSXp5/txvL5T9P0k/bneeEfHziNhrYCIcGDmZPpXX8x8kfU3SkBbbzpD0g+q0iJgYEd+rJ1oDJ4gtiqTtgcuBbwI7ALsC/wQ80+Z8hg58dPwwIrYFRgE3ApdKUg3v05fdgcUdfk8i4k/AD4ETq9PzxvMEoK2NYE3rZ6Dsm9fzEcBk4JQux2N9iQi/tpAXMB5Y00+dTwB3A08AdwH75+nLgC8At5MSylDgbcBNwBrgNuDIynxeCXwHuB/4A/C/gSFN3nMG8IPK+D5AACOBk4EbK2UHAwuAx/Lfg/P0fwGeB/4EPAl8q8l7vY+UBNYA1wN/lqdf29D+DQ3tivPPcU4FfgOsBs4GVGl3Sl6eq4Ergd2bxHVwXuavqEw7GngoL+uPVdbLfcBfV+odCazI6+cB4Pu90yp1pgO/razXYytlJ5OS8ldynL8DJlbKdwD+HViZyy+rlL0HWJSX503Am/r4bgXw+sr4JcDZlfGvA8uBx4GFwGF5+gTgWeC5vOxvy9OvB07Nw1sBXwR+n5fZ+cAru/0/t6m/uh6AXx1c2bA98AjpF+lE4FUN5R8kbczfCgh4fe8GjZQgFgFjgG1Iex+P5I3YVsC78vioXP8y4N+A4cCrgVuqG7WG951BThDAy4AvA8vz+MnkBJE3VKuBj+aN5gl5fMdc/sIGo8n7vAF4Kse6NemQ0lJgWIvt1yvPG73LgRHAbsAqYEIue3+e/5/leL8I3NTH/O8FPlIZvwj41zx8DPC6vF6OAJ7mxeR9JLAWOCsvv21YP0F8ENglr6vJeTnsXFnGz5F+HAwBPklKBsrlV5D2cF6Vl9sRefr+pI3xgbndSfl78rImn++FBAHsTfrx8NlK+UeAHfOy+hwp2b288TtSWh+kRLwUeC2wLXAp8P1u/89t6q+uB+BXh1d42lh9l/SLcy0wF9gpl10JfKZJu2XAKZXxLzT+A+b2JwE7kfYytqmUnQBc12TeM0i/ENfkDc61wFty2cm8mCA+CtzS0PaXwMl5+IUNRpP3+V/AJZXxrUgJ8cgW269Xnjd6h1bGLwGm5+H5wMcb3u9pmu9FfBG4Kg9vn+u+uUndy3rXFSkZPNu7Ma1MW9HHZ1kETKos46WVslfkz/UaYGdgHQ0/JnK9c4AvNUxbQk4ghfpB2jt4Kg9fRJNkkuuvJh2S6v2O9JUgrgH+plK2FynpDe3U/9bm+PI5iC1MRNwdESdHxGjgjaRflf+ai8eQDkM0s7wyvDvwwXxydY2kNcChpA3K7qRfmvdXyv6NtCfRzCURMSIiXh0Rb4+IhYU6u5AOIVT9nrQ304qXtI+Idfkztdq+mQcqw0+TfsFCWg5fryyDR0l7AM3e73zgKEm7AseRNtq/BpA0UdLN+cKCNaQ9t5GVtqsincsoknSipEWVWN7Y0P6FzxART+fBbUnfiUcjYnVhtrsDn2v4DowhLedm9s/znUza8xheifFzku7OF1CsIR2mHFmcy/oavxu/J+2J7NRieytwgtiCRcQ9pL2JN+ZJy0mHMZo2qQwvJ+1BjKi8hkfEmbnsGWBkpWz7iNhnI0NeSdooVe1G2gtojK/f9vkk+JhK+/602/XxctJhteoy2iYibirOPOK/gJ8DHybtLZ2f43wZ8BPSOYKdImIEMI+UbPqNTdLuwLnANNLhuBHAnQ3t+/oMO0ga0aTsXxo+3ysi4qK+ZhjJJaS9vzNyjIeR9kr/irS3MoJ0nqk3xrbWLel7sRZ4sJ921gcniC2IpL3zr7TReXwM6dDPzbnKecDpkt6i5PV541LyA+C9kv5C0pB8qeaRkkZHxP3AVcBXJW0vaStJr5N0xEZ+hHnAGyR9SNJQSZOBcaRzAJA2Bq/to/0lwDGS3iFpa9Jx7mdIJ1db0d/8G80E/qekfQAkvVLSB/tp8z3ShvwQ4II8bRjp3MIqYK2kicC724hjOGkDuyrH8TFe/FHQp7wu5wPflvQqSVtLOjwXnwtMlXRg/r4Ml3SMpO1ajOtMYIqk1wDbkTboq4Chks4gHWbr9SAwVlKzbdZFwGcl7SFpW+D/kK6MW9tiLFbgBLFleYK0W/8rSU+REsOdpA0lEfEj0tU6F+a6l5FODK8nIpYDk4C/J/1TLwf+By9+p04kbdjuIh1L/jHp8NMGi4hHSFfNfI50QvzzwHsi4uFc5evAcZJWS1rvPoaIWEI6EfpN4GHgvcB7I+LZFkPoc/6F95tDOnF8saTHSct6Yj/Nfkw6GXxN3jgTEU8AnyYluNXAh0jnjloSEXcBXyX9Yn8Q+HPgF622J+3NPAfcQzpHdFqebw/pxPa3clxLSeczWo3rDuBnpO/NlaREdC/p8NCfeOkhzR/lv49IurUwu9mkq7duIF2F9Sfgb1uNxcp6r1IwMzN7Ce9BmJlZkROEmZkVOUGYmVmRE4SZmRUN5k692jZy5MgYO3Zst8MwM9tkLFy48OGIGFUq26wSxNixY+np6el2GGZmmwxJjb0TvMCHmMzMrMgJwszMipwgzMysyAnCzMyKak0QkiZIWiJpqaTphfJJkm7P3RD3SDq01bZmZlav2hJEfp7u2aTOycYBJ0ga11DtGtIDQfYjPRHqvDbamplZjercgziA9MCT+3JvmReTev98QUQ8GS/2FtjbJXFLbc3MrF51JohdeWl3vSsoPElL0rGS7iE99/aUdtrm9lPy4ameVatWDUjgZmZWb4IoPa1qvb7FI2JOROxNesD7l9ppm9vPiojxETF+1KjizYBmZrYB6ryTegXpcY69RpMeC1gUETfkp46NbLftQBg7/Yq26i8785iaIjEzGxzq3INYAOyZHwE4DDiehqdg5UdaKg/vT3oC2SOttDUzs3rVtgcREWslTSM9SnAIMDsiFkuamstnAh8ATpT0HPBHYHI+aV1sW1esZma2vlo764uIeaQHzVenzawMn0V6Zm9Lbc3MrHN8J7WZmRU5QZiZWZEThJmZFTlBmJlZkROEmZkVOUGYmVmRE4SZmRU5QZiZWZEThJmZFTlBmJlZkROEmZkVOUGYmVmRE4SZmRU5QZiZWZEThJmZFTlBmJlZkROEmZkVOUGYmVmRE4SZmRU5QZiZWZEThJmZFTlBmJlZkROEmZkVOUGYmVmRE4SZmRU5QZiZWVGtCULSBElLJC2VNL1Q/mFJt+fXTZL2rZQtk3SHpEWSeuqM08zM1je0rhlLGgKcDbwLWAEskDQ3Iu6qVPsdcERErJY0EZgFHFgpPyoiHq4rRjMza67OPYgDgKURcV9EPAtcDEyqVoiImyJidR69GRhdYzxmZtaGOhPErsDyyviKPK2ZjwPzK+MBXCVpoaQpzRpJmiKpR1LPqlWrNipgMzN7UW2HmAAVpkWxonQUKUEcWpl8SESslPRq4GpJ90TEDevNMGIW6dAU48ePL87fzMzaV+cexApgTGV8NLCysZKkNwHnAZMi4pHe6RGxMv99CJhDOmRlZmYdUmeCWADsKWkPScOA44G51QqSdgMuBT4aEfdWpg+XtF3vMPBu4M4aYzUzswa1HWKKiLWSpgFXAkOA2RGxWNLUXD4TOAPYEfi2JIC1ETEe2AmYk6cNBS6MiJ/WFauZma2vznMQRMQ8YF7DtJmV4VOBUwvt7gP2bZxuZmad4zupzcysyAnCzMyKnCDMzKzICcLMzIqcIMzMrMgJwszMipwgzMysyAnCzMyKnCDMzKzICcLMzIqcIMzMrMgJwszMipwgzMysyAnCzMyKnCDMzKzICcLMzIqcIMzMrMgJwszMipwgzMysyAnCzMyKnCDMzKzICcLMzIqcIMzMrMgJwszMipwgzMysqNYEIWmCpCWSlkqaXij/sKTb8+smSfu22tbMzOpVW4KQNAQ4G5gIjANOkDSuodrvgCMi4k3Al4BZbbQ1M7Ma1bkHcQCwNCLui4hngYuBSdUKEXFTRKzOozcDo1tta2Zm9aozQewKLK+Mr8jTmvk4MH8D25qZ2QAbWuO8VZgWxYrSUaQEcegGtJ0CTAHYbbfd2o/SzMyK6tyDWAGMqYyPBlY2VpL0JuA8YFJEPNJOW4CImBUR4yNi/KhRowYkcDMzqzdBLAD2lLSHpGHA8cDcagVJuwGXAh+NiHvbaWtmZvWq7RBTRKyVNA24EhgCzI6IxZKm5vKZwBnAjsC3JQGszXsDxbZ1xWpmZuur8xwEETEPmNcwbWZl+FTg1FbbmplZ5/hOajMzK3KCMDOzIicIMzMrcoIwM7MiJwgzMytygjAzsyInCDMzK+o3QUjaSdJ3JM3P4+Mkfbz+0MzMrJta2YP4LumO5l3y+L3AaTXFY2Zmg0QrCWJkRFwCrIPUhQbwfK1RmZlZ17WSIJ6StCO5u21JbwMeqzUqMzPrulb6Yvo7Uk+qr5P0C2AUcFytUZmZWdf1myAi4lZJRwB7kR7ksyQinqs9MjMz66pWrmL6FLBtRCyOiDuBbSX9Tf2hmZlZN7VyDuITEbGmdyQiVgOfqC0iMzMbFFpJEFspP80HQNIQYFh9IZmZ2WDQyknqK4FLJM0kXck0FfhprVGZmVnXtZIgvgD8NfBJ0knqq4Dz6gzKzMy6r5WrmNYB5+SXmZltIfpNEJIOAWYAu+f6AiIiXltvaGZm1k2tHGL6DvBZYCHuYsPMbIvRSoJ4LCLm1x6JmZkNKq0kiOskfRm4FHimd2JE3FpbVGZm1nWtJIgD89/xlWkBvH3gwzEzs8GilauYjupEIGZmNri0sgeBpGOAfYCX906LiH+uKygzM+u+VjrrmwlMBv6WdInrB0mXvPZL0gRJSyQtlTS9UL63pF9KekbS6Q1lyyTdIWmRpJ6WPo2ZmQ2YVvpiOjgiTgRWR8Q/AQcBY/prlPtsOhuYCIwDTpA0rqHao8Cnga80mc1REbFfRIxvUm5mZjVpJUH8Mf99WtIuwHPAHi20OwBYGhH3RcSzwMXApGqFiHgoIhbkeZqZ2SDSSoK4XNII4MvArcAy0sa+P7sCyyvjK/K0VgVwlaSFkqY0qyRpiqQeST2rVq1qY/ZmZtaXVq5i+lIe/Imky4GXR0Qrz6RWYVq0EdshEbFS0quBqyXdExE3FOKbBcwCGD9+fDvzNzOzPjRNEJLeHhHXSvrLQhkRcWk/817BS89VjAZWthpYRKzMfx+SNId0yGq9BGFmZvXoaw/iCOBa4L2FsiDdWd2XBcCekvYA/gAcD3yolaAkDQe2iogn8vC7AV9Wa2bWQU0TRET8o6StgPkRcUm7M46ItZKmkR44NASYHRGLJU3N5TMlvQboAbYH1kk6jXTF00hgTn6Q3VDgwojwQ4rMzDqoz3MQEbEub+TbThC5/TxgXsO0mZXhB0iHnho9Duy7Ie9pZmYDo5WrmK6WdLqkMZJ26H3VHpmZmXVVK11tnJL/fqoyLQA/MMjMbDPWymWurdwUZ2Zmm5lWO+t7I+nkcbWzvvPrCsrMzLqvlWdS/yNwJClBzCP1rXQj4ARhZrYZa+Uk9XHAO4AHIuJjpKuLXlZrVGZm1nWtJIg/RcQ6YK2k7YGH8AlqM7PNXl9dbXwLuAi4JXfWdy6wEHgSuKUj0ZmZWdf0dQ7iN6TnNOxCSgoXAe8Cto+I2zsQm5mZdVHTQ0wR8fWIOAg4nPRgn38H5gPvl7Rnh+IzM7Mu6fccRET8PiLOiog3kzrbOxa4p/bIzMysq1p5JvXWkt4r6QLSHsS9wAdqj8zMzLqqr5PU7wJOAI4hnZS+GJgSEU91KDYzM+uivk5S/z1wIXB6RDzaoXjMzGyQ6Ot5EEd1MhAzMxtcWrlRzszMtkBOEGZmVuQEYWZmRU4QZmZW5ARhZmZFThBmZlbkBGFmZkVOEGZmVuQEYWZmRU4QZmZW5ARhZmZFtSYISRMkLZG0VNL0Qvnekn4p6RlJp7fT1szM6tVXb64bRdIQ4GzSY0pXAAskzY2IuyrVHgU+Dbx/A9oOGmOnX9FW/WVnHlNTJGZmA6fOPYgDgKURcV9EPEt6nsSkaoWIeCgiFgDPtdvWzMzqVWeC2BVYXhlfkacNaFtJUyT1SOpZtWrVBgVqZmbrqzNBqDAtBrptRMyKiPERMX7UqFEtB2dmZn2rM0GsAMZUxkcDKzvQ1szMBkCdCWIBsKekPSQNA44H5nagrZmZDYDarmKKiLWSpgFXAkOA2RGxWNLUXD5T0muAHmB7YJ2k04BxEfF4qW1dsZqZ2fpqSxAAETEPmNcwbWZl+AHS4aOW2pqZWef4TmozMytygjAzsyInCDMzK3KCMDOzIicIMzMrcoIwM7MiJwgzMytygjAzsyInCDMzK3KCMDOzIicIMzMrcoIwM7MiJwgzMytygjAzs6Jau/u21oydfkVb9ZedeUxNkZiZvch7EGZmVuQEYWZmRU4QZmZW5ARhZmZFThBmZlbkBGFmZkVOEGZmVuQEYWZmRU4QZmZW5ARhZmZFThBmZlZUa4KQNEHSEklLJU0vlEvSN3L57ZL2r5Qtk3SHpEWSeuqM08zM1ldbZ32ShgBnA+8CVgALJM2NiLsq1SYCe+bXgcA5+W+voyLi4bpiNDOz5urcgzgAWBoR90XEs8DFwKSGOpOA8yO5GRghaecaYzIzsxbVmSB2BZZXxlfkaa3WCeAqSQslTWn2JpKmSOqR1LNq1aoBCNvMzKDeBKHCtGijziERsT/pMNSnJB1eepOImBUR4yNi/KhRozY8WjMze4k6E8QKYExlfDSwstU6EdH79yFgDumQlZmZdUidCWIBsKekPSQNA44H5jbUmQucmK9mehvwWETcL2m4pO0AJA0H3g3cWWOsZmbWoLarmCJiraRpwJXAEGB2RCyWNDWXzwTmAUcDS4GngY/l5jsBcyT1xnhhRPy0rljNzGx9tT6TOiLmkZJAddrMynAAnyq0uw/Yt87YzMysb76T2szMipwgzMysyAnCzMyKaj0HYfUbO/2KtuovO/OYmiIxs82N9yDMzKzIexBbsHb3PsB7IGZbEu9BmJlZkROEmZkVOUGYmVmRE4SZmRU5QZiZWZGvYrIN5nswzDZvThDWFU4uZoOfE4Rtcnz/hlln+ByEmZkVOUGYmVmRE4SZmRU5QZiZWZEThJmZFfkqJtvi+BJbs9Y4QZi1wcnFtiROEGYd5ARjmxInCLNNxMYkF99caBvCCcLM+tXJ5OTENHg4QZjZoLWxez5ObBvHCcLMbIB1M7ENpFrvg5A0QdISSUslTS+US9I3cvntkvZvta2ZmdWrtgQhaQhwNjARGAecIGlcQ7WJwJ75NQU4p422ZmZWozr3IA4AlkbEfRHxLHAxMKmhziTg/EhuBkZI2rnFtmZmViNFRD0zlo4DJkTEqXn8o8CBETGtUudy4MyIuDGPXwN8ARjbX9vKPKaQ9j4A9gKWFMIZCTw8QB9tIDmu9g3W2AZrXDB4YxusccHgja2OuHaPiFGlgjpPUqswrTEbNavTSts0MWIWMKvPQKSeiBjfV51ucFztG6yxDda4YPDGNljjgsEbW6fjqjNBrADGVMZHAytbrDOshbZmZlajOs9BLAD2lLSHpGHA8cDchjpzgRPz1UxvAx6LiPtbbGtmZjWqbQ8iItZKmgZcCQwBZkfEYklTc/lMYB5wNLAUeBr4WF9tNyKcPg9BdZHjat9gjW2wxgWDN7bBGhcM3tg6GldtJ6nNzGzT5gcGmZlZkROEmZkVbTYJYmO69ag5rjGSrpN0t6TFkj5TqHOkpMckLcqvMzoU2zJJd+T37CmUd2uZ7VVZFoskPS7ptIY6HVlmkmZLekjSnZVpO0i6WtJv8t9XNWlba3cxTWL7sqR78vqaI2lEk7Z9rvsa4poh6Q+V9XV0k7bdWGY/rMS1TNKiJm3rXGbF7UTXv2sRscm/SCeyfwu8lnSJ7G3AuIY6RwPzSfdYvA34VYdi2xnYPw9vB9xbiO1I4PIuLLdlwMg+yruyzArr9gHSzTwdX2bA4cD+wJ2Vaf8XmJ6HpwNnNYm7z+9kTbG9Gxiah88qxdbKuq8hrhnA6S2s644vs4byrwJndGGZFbcT3f6ubS57EBvTrUetIuL+iLg1Dz8B3A3sWvf7DpCuLLMG7wB+GxG/7/D7AhARNwCPNkyeBHwvD38PeH+hae3dxZRii4irImJtHr2ZdA9RRzVZZq3oyjLrJUnAXwEXDeR7tqKP7URXv2ubS4LYFVheGV/B+hvhVurUStJY4M3ArwrFB0m6TdJ8Sft0KKQArpK0UKnLkkZdX2ake2Ca/cN2Y5kB7BTpfh3y31cX6gyGZXcKaQ+wpL91X4dp+dDX7CaHSrq9zA4DHoyI3zQp78gya9hOdPW7trkkiI3p1qMjJG0L/AQ4LSIebyi+lXQIZV/gm8BlHQrrkIjYn9Rr7qckHd5Q3u1lNgx4H/CjQnG3llmrur3s/gFYC1zQpEp/636gnQO8DtgPuJ90KKdRV5cZcAJ97z3Uvsz62U40bVaYNiDLbXNJEBvTrUftJG1NWukXRMSljeUR8XhEPJmH5wFbSxpZd1wRsTL/fQiYQ9pVreraMssmArdGxIONBd1aZtmDvYfa8t+HCnW6+X07CXgP8OHIB6kbtbDuB1REPBgRz0fEOuDcJu/XzWU2FPhL4IfN6tS9zJpsJ7r6XdtcEsTGdOtRq3xc8zvA3RHxtSZ1XpPrIekA0np5pOa4hkvarneYdHLzzoZqXVlmFU1/0XVjmVXMBU7KwycB/1Go05XuYiRNIPWI/L6IeLpJnVbW/UDHVT13dWyT9+tmFzvvBO6JiBWlwrqXWR/bie5+1+o4I9+NF+mKm3tJZ/P/IU+bCkzNwyI9hOi3wB3A+A7FdShpd+92YFF+Hd0Q2zRgMenqg5uBgzsQ12vz+92W33vQLLP83q8gbfBfWZnW8WVGSlD3A8+Rfql9HNgRuAb4Tf67Q667CzCvr+9kB2JbSjoe3ftdm9kYW7N1X3Nc38/fodtJG6+dB8syy9O/2/vdqtTt5DJrtp3o6nfNXW2YmVnR5nKIyczMBpgThJmZFTlBmJlZkROEmZkVOUGYmVmRE4TZZkbSfs16SzVrhxOE2eZnP9J18WYbxQnCNluSxub+9c/NfexfJWmbQr2dlJ6dcFt+HZyn/52kO/PrtMo875F0Xp5+gaR3SvpF7rP/gFxvhqTvS7o2T/9Eni6lZzbcqfRsgcl5+pGSrpf04zz/Cyp3ir9F0s9yJ3FXVrpeuF7SWZJukXSvpMPynbT/DExWem7BZElH6MXnHfy6945gs34N9J2Kfvk1WF7AWFKHdfvl8UuAjxTq/ZDUORqkvvVfCbyFdOfvcGBb0t2zb67M889JP7AWArNJd51PAi7L85lBuut2G2Ak6e7mXYAPAFfn99kJ+C/SswCOBB4j9aOzFfBL0t21WwM3AaPyfCcDs/Pw9cBX8/DRwP/PwycD36p8vv8kdTRH/ixDu71u/No0XkM3NLGYbSJ+FxGL8vBC0ga+0duBEwEi4nngMUmHAnMi4ikASZeSuoOem+d5R56+GLgmIkLSHQ3z/4+I+CPwR0nXkTp3OxS4KL/Pg5J+BrwVeBy4JXJfQEpPNRsLrAHeCFyddyiGkLqK6NXbqVuzzwbwC+Brki4ALo0m/Q2ZNXKCsM3dM5Xh50m/6FtR6kK5NM91lfF1vPR/qrEfm2hjvs/neQlYHBEH9dOmt/56IuJMSVeQ9jJulvTOiLinjzjMAJ+DMIPUCdonASQNkbQ9cAPwfkmvyL13Hgv8vM35TpL0ckk7kg4hLcjznZzfZxTpEZi39DGPJcAoSQfl+LZW/w9HeoL02Epym9dFxB0RcRbQA+zd5uewLZQThBl8BjgqHyJaCOwT6fGP3yVtvH8FnBcRv25zvrcAV5B6m/1SpOcJzCH12HkbcC3w+Yh4oNkMIj1C8jjgLEm3kXr5PLif970OGNd7kho4LZ8Uvw34I82fMmf2Eu7N1awGkmYAT0bEV7odi9mG8h6EmZkVeQ/CzMyKvAdhZmZFThBmZlbkBGFmZkVOEGZmVuQEYWZmRf8NbABbKLF36pAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Checking how PCA works out on the scree plot \n",
    "from sklearn import decomposition\n",
    "\n",
    "# We will by looking at how much variance we get \n",
    "n_components = 20\n",
    "\n",
    "pca = decomposition.PCA(n_components = n_components)\n",
    "X_PCA_train = pca.fit_transform(X_train)\n",
    "X_PCA_test = pca.fit_transform(X_test)\n",
    "\n",
    "print(\"Data shape:\", X_PCA_train.shape, X_PCA_test.shape)\n",
    "\n",
    "# Plot the variance on a scree plot \n",
    "def plot_scree(n_comp, pca_var):\n",
    "    plt.bar(np.linspace(1, n_comp, n_comp),pca_var)\n",
    "\n",
    "    plt.title(\"Scree Plot of the Variance Ratio\")\n",
    "    plt.xlabel(\"n components\")\n",
    "    plt.ylabel(\"Variance\")\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "plot_scree(n_components, pca.explained_variance_ratio_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using multiple n_comps \n",
    "\n",
    "Here, we trying to measure the training and testing score using different n_comps for our PCA and logreg. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCA_logreg_metrics(X_train, X_test, y_train, y_test, n_comps): \n",
    "    \"\"\"\n",
    "    This function aims to check on the training and testing \n",
    "    scores with varying n_commponents set for the PCA. \n",
    "    \n",
    "    Input: data \n",
    "    Output: Training and testing scores \n",
    "    \"\"\"\n",
    "    # Metrics \n",
    "    training_scores = []\n",
    "    testing_scores = []\n",
    "    \n",
    "    for n in n_comps: \n",
    "        # Fit PCA \n",
    "        pca = decomposition.PCA(n_components = n)\n",
    "        X_PCA_train = pca.fit_transform(X_train)\n",
    "        X_PCA_test = pca.fit_transform(X_test)\n",
    "        \n",
    "        # Fit LogReg \n",
    "        logreg = LogisticRegression(max_iter=100)\n",
    "        logreg.fit(X_PCA_train, y_train)\n",
    "        \n",
    "        training_scores.append(logreg.score(X_PCA_train, y_train))\n",
    "        testing_scores.append(logreg.score(X_PCA_test, y_test))\n",
    "        \n",
    "    return training_scores, testing_scores "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "# Get number of components from 1 to 99 \n",
    "n_comps = np.linspace(1, 49, 49).astype('int64')\n",
    "\n",
    "training_scores, testing_scores = PCA_logreg_metrics(X_train, X_test, y_train, y_test, n_comps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results \n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize = [15,5])\n",
    "\n",
    "ax[0].plot(n_comps, training_scores, label = 'training')\n",
    "ax[0].plot(n_comps, testing_scores, label = 'testing')\n",
    "ax[0].set_title(\"Training vs Testing scores using PCA\")\n",
    "ax[0].set_xlabel(\"n_components\")\n",
    "ax[0].set_ylabel(\"score\")\n",
    "ax[0].legend()\n",
    "\n",
    "ax[1].plot(n_comps[0:15], training_scores[0:15], label = 'training')\n",
    "ax[1].plot(n_comps[0:15], testing_scores[0:15], label = 'testing')\n",
    "ax[1].set_title(\"Training vs Testing scores using PCA (Zoomed in)\")\n",
    "ax[1].set_xlabel(\"n_components\")\n",
    "ax[1].set_ylabel(\"score\")\n",
    "ax[1].legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTES**\n",
    "\n",
    "0 - 10: good measure of n_components with high testing score \n",
    "\n",
    "15 and beyond: starting to overfit "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best PCA parameters\n",
    "\n",
    "Based on the plot, I tried on different n_comps between 1-15 since it has the highest pair of training and testing scores. I ended up with 5. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will by looking at how much variance we get \n",
    "n_components = 5\n",
    "\n",
    "pca = decomposition.PCA(n_components = n_components)\n",
    "X_PCA_train = pca.fit_transform(X_train)\n",
    "X_PCA_test = pca.fit_transform(X_test)\n",
    "\n",
    "logreg_PCA = LogisticRegression(max_iter=100)\n",
    "\n",
    "logreg_PCA.fit(X_PCA_train, y_train)\n",
    "\n",
    "logreg_pred = logreg_PCA.predict(X_PCA_test)\n",
    "\n",
    "# Acquire Metrics \n",
    "logreg_PCA_training_score = logreg_PCA.score(X_PCA_train, y_train)\n",
    "logreg_PCA_testing_score = logreg_PCA.score(X_PCA_test, y_test)\n",
    "\n",
    "print(\"---SCORES---\")\n",
    "print(\"Training Score:\", logreg_PCA_training_score)\n",
    "print(\"Testing Score:\", logreg_PCA_testing_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix \n",
    "metrics.plot_confusion_matrix(logreg_PCA, X_PCA_test, y_test, cmap = 'binary')\n",
    "plt.title(\"Logreg with PCA\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experimenting PCA with CV \n",
    "\n",
    "Based on the observations in the graph, we noticed that the data tends to overfit once we increase the number of components. With n_comp higher than 400, the testing score reaches over 0.9 and testing score is approx. 0.5. I experimented with using this n_comp and performing CV with the LogReg model using PCA-transformed X_train and X_test and did not see any improvements. The mode had a less overfit but with a low testing score (training = 0.7, testing = 0.54). \n",
    "\n",
    "I did not paste the code here anymore since I considered this as exploratory and will not be used for the analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression with LDA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement LDA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Fitting LDA \n",
    "lda = LinearDiscriminantAnalysis()\n",
    "\n",
    "X_LDA_train = lda.fit_transform(X_train, y_train)\n",
    "X_LDA_test = lda.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See how our LDA performs \n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize = [15,5])\n",
    "\n",
    "ax[0].hist(X_LDA_train)\n",
    "ax[0].set_title(f\"Training with LDA score {lda.score(X_train,y_train)}\") \n",
    "ax[0].set_xlabel(\"X_LDA values\")\n",
    "ax[1].hist(X_LDA_test)\n",
    "ax[1].set_title(f\"Testing with LDA score {lda.score(X_test,y_test)}\")\n",
    "ax[1].set_xlabel(\"X_LDA values\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing with LogReg \n",
    "\n",
    "logreg_LDA = LogisticRegressionCV()\n",
    "\n",
    "# Tried using CV and still does not change anything. \n",
    "# logreg_LDA = LogisticRegressionCV(cv = 10, random_state = 0)\n",
    "\n",
    "logreg_LDA.fit(X_LDA_train, y_train)\n",
    "\n",
    "logreg_pred = logreg_LDA.predict(X_LDA_test)\n",
    "\n",
    "# Acquire Metrics \n",
    "logreg_LDA_training_score = logreg_LDA.score(X_LDA_train, y_train)\n",
    "logreg_LDA_testing_score = logreg_LDA.score(X_LDA_test, y_test)\n",
    "\n",
    "print(\"---SCORES---\")\n",
    "print(\"Training Score:\", logreg_LDA_training_score)\n",
    "print(\"Testing Score:\", logreg_LDA_testing_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTE \n",
    "\n",
    "For the LDA model, I also performed a validation stepped where I tried different regularization parameters but it does not change the training and testing score and it is always equal to the LDA training and testing score after fitting to the logistic regression. I also attempted to apply the same process in linear SVM but the results were the same. Therefore, the LDA tends to overfit with the training data and resulting in a worse classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix \n",
    "metrics.plot_confusion_matrix(logreg_LDA, X_LDA_test, y_test, cmap  = 'binary')\n",
    "plt.title(\"Logreg with LDA\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of Analysis \n",
    "\n",
    "\n",
    "For this analysis, we will be looking at the confusion matrices and the scores of each of the model for comparison. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,3, figsize = [20,5])\n",
    "\n",
    "classifiers = [logregCV, logreg_PCA, logreg_LDA]\n",
    "titles = ['LogReg', 'LogReg with PCA', 'LogReg with LDA'] \n",
    "X = [X_test, X_PCA_test, X_LDA_test]\n",
    "\n",
    "counter = 0 \n",
    "for cls, ax in zip(classifiers, axes.flatten()):\n",
    "    metrics.plot_confusion_matrix(cls, \n",
    "                          X[counter], \n",
    "                          y_test, \n",
    "                          ax=ax, \n",
    "                          cmap='Blues')\n",
    "    ax.set_title(titles[counter])\n",
    "    counter += 1 \n",
    "plt.show() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Testing Scores Table \n",
    "\n",
    "|                | LogRegCV | LogReg with PCA  | LogReg with LDA |\n",
    "|----------------|--------|------------------|-----------------|\n",
    "| Training Score | 0.7531 | 0.6302           | 0.9990          |\n",
    "| Testing Score  | 0.6302 | 0.6004           | 0.5547          |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix\n",
    "\n",
    "A common occurrence for all models is the error in predicting male clothing where a majority of the images for the male clothing is categorized as female. A main reason for this problem is perhaps the noise in the male data set where some pictures have females in them and is very noisy in terms of the type of photo. Some photos are group photos of people wearing multiple clothes. To improve this, we might want to clean out the data set and select the only ones that can represent clothes only and not other individuals or other variables that are present in the photos. For all models, they seem to have more correct predictions that errors which is a good sign and the best model that is performing is the Logistic regression with the PCA. \n",
    "\n",
    "\n",
    "### Training and Testing Scores \n",
    "\n",
    "**BEST MODEL: Logistic Regression**\n",
    "\n",
    "For the logistic regression, we performed a cross-validation step since our logistic regression tends to overfit when n_features > n_samples of the data. After optimizing for the regularization parameter, Logistic Regression with CV is the best model compared to LogReg with PCA or LDA with the highest testing score. Compared to LogReg with PCA based on the confusion matrix, it performs slightly better in classifying male clothing photos with regards to correct classification. \n",
    "\n",
    "**Logistic Regression with the PCA** \n",
    "\n",
    "The application of PCA to the Logistic regression comes second in this analysis. First, I look into the scree plot to see how the number of components change the variation captured by the transformation. Then, I tried different n_comps to transform the data set. Looking back to that plot, the model seems to improve itself as we increase the number of components from 1 to 10. Beyond that number of components, the model starts to overfit and its testing scores are significantly diminished. Even after using CV at higher dimensions, the testing score cannot be improved. Our best n_comp value = 5 and the results are shown in the table above. \n",
    "\n",
    "**Logistic Regression with LDA** \n",
    "\n",
    "Applying LDA to the model and using logistic regression seemed to overfit the training data by alot with a training score of almost 1. The testing score 0.55 is worse makes it the worst model for this analysis. I also tried using a validation step but changing the regularization parameter doesn't seem to change the training and testing score. I also tried using the Linear SVM instead of a logistic regression and the training and testing scores are still the same.\n",
    "\n",
    "\n",
    "### Recommendations \n",
    "\n",
    "Based on our results, the logistic regression with cross validation (LogRegCV) is our best bet in doing the job for classifying male and female clothing since it has the best testing score and does not overfit. With specific adjustments to the logistic regression for its tolerance and standardizing the data, we are able to perform a good classification model despite a very noisy data set. \n",
    "\n",
    "However, this is only for our own data set and we must take note that we performed resizing in our images and that our data set is very noisy. Other improvements would be cleaning our data and checking for photos that do not really represent the proper class that we are aiming for (some photos are just group photos of people with both male and female individuals included). \n",
    "\n",
    "Lastly, we can also consider using other models such as LinearSVM and KNN since Logistic Regression's disadvantage is overfitting when n_features > n_samples. We needed to increase its tolerance for convergence and may have affected with the accuracy of our predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
